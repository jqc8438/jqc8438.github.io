<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>【论文笔记】GAN基础与代码解读（GAN、CGAN、pix2pix、CycleGAN） - Jinhaha&#39;s blog</title><meta name="description" content="（GAN、CGAN、pix2pix、CycleGAN）"><meta property="og:title" content="【论文笔记】GAN基础与代码解读（GAN、CGAN、pix2pix、CycleGAN）" />
<meta property="og:description" content="（GAN、CGAN、pix2pix、CycleGAN）" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://www.jqc8438.top/2021/11/gan/" /><meta property="og:image" content="http://www.jqc8438.top/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-11-02T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-11-02T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="http://www.jqc8438.top/logo.png"/>

<meta name="twitter:title" content="【论文笔记】GAN基础与代码解读（GAN、CGAN、pix2pix、CycleGAN）"/>
<meta name="twitter:description" content="（GAN、CGAN、pix2pix、CycleGAN）"/>
<meta name="application-name" content="jinhaha">
<meta name="apple-mobile-web-app-title" content="jinhaha"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://www.jqc8438.top/2021/11/gan/" /><link rel="prev" href="http://www.jqc8438.top/2021/10/lvm/" /><link rel="next" href="http://www.jqc8438.top/2021/11/miniconda/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "【论文笔记】GAN基础与代码解读（GAN、CGAN、pix2pix、CycleGAN）",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/www.jqc8438.top\/2021\/11\/gan\/"
        },"genre": "posts","keywords": "GAN, 生成对抗网络","wordcount":  5600 ,
        "url": "http:\/\/www.jqc8438.top\/2021\/11\/gan\/","datePublished": "2021-11-02T00:00:00+00:00","dateModified": "2021-11-02T00:00:00+00:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "jinhaha"
            },"description": "（GAN、CGAN、pix2pix、CycleGAN）"
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">('true' === 'true' && window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Jinhaha&#39;s blog"><span class="header-title-pre"><i class='fas fa-laptop-code fa-fw'></i></span>金哈哈的blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"><i class='fas fa-archive'></i> 归档 </a><a class="menu-item" href="/tags/"><i class='fas fa-tags'></i> 标签 </a><a class="menu-item" href="/categories/"><i class='fas fa-th'></i> 分类 </a><a class="menu-item" href="/about/"><i class='fas fa-address-card'></i> 关于 </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Jinhaha&#39;s blog"><span class="header-title-pre"><i class='fas fa-laptop-code fa-fw'></i></span>金哈哈的blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title=""><i class='fas fa-archive'></i>归档</a><a class="menu-item" href="/tags/" title=""><i class='fas fa-tags'></i>标签</a><a class="menu-item" href="/categories/" title=""><i class='fas fa-th'></i>分类</a><a class="menu-item" href="/about/" title=""><i class='fas fa-address-card'></i>关于</a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">【论文笔记】GAN基础与代码解读（GAN、CGAN、pix2pix、CycleGAN）</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>jinhaha</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><i class="far fa-folder fa-fw"></i>论文笔记</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2020-11-02">2020-11-02</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 5600 字&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 12 分钟&nbsp;</div>
        </div><div class="featured-image"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="/images/GAN.jpg"
        data-srcset="/images/GAN.jpg, /images/GAN.jpg 1.5x, /images/GAN.jpg 2x"
        data-sizes="auto"
        alt="/images/GAN.jpg"
        title="（GAN、CGAN、pix2pix、CycleGAN）" /></div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#写在前面">写在前面</a></li>
    <li><a href="#一gan">一、【GAN】</a>
      <ul>
        <li><a href="#1-概要">1. 概要</a></li>
        <li><a href="#2-基本架构">2. 基本架构</a></li>
        <li><a href="#3-vae">3. VAE</a></li>
        <li><a href="#4-gan">4. GAN</a></li>
        <li><a href="#5-value-function">5. Value function</a></li>
        <li><a href="#6-训练流程">6. 训练流程</a></li>
        <li><a href="#7代码">7.代码</a></li>
      </ul>
    </li>
    <li><a href="#二cgan">二、【CGAN】</a>
      <ul>
        <li><a href="#1-概要-1">1. 概要</a></li>
        <li><a href="#2多模态学习和图像描述">2.多模态学习和图像描述</a></li>
        <li><a href="#3-网络结构">3. 网络结构</a></li>
        <li><a href="#4-实验">4. 实验</a>
          <ul>
            <li><a href="#单模态任务手写数字识别">单模态任务【手写数字识别】</a></li>
            <li><a href="#多模态任务有图像有文本">多模态任务【有图像有文本】</a></li>
          </ul>
        </li>
        <li><a href="#5代码">5.代码</a></li>
      </ul>
    </li>
    <li><a href="#三pix2pix">三、【pix2pix】</a>
      <ul>
        <li><a href="#1-概要-2">1. 概要</a></li>
        <li><a href="#2-网络结构">2. 网络结构</a></li>
      </ul>
    </li>
    <li><a href="#四cyclegan">四、【CycleGAN】</a>
      <ul>
        <li><a href="#1-概要-3">1. 概要</a></li>
        <li><a href="#2-网络结构和设计框架">2. 网络结构和设计框架</a></li>
        <li><a href="#3-损失函数">3. 损失函数</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h2 id="写在前面">写在前面</h2>
<p>之前看到视网膜血管分割的，有很多用GAN做的。然后就主要是对GAN的一些基础知识的学习，大概了解一下gan的思想。主要就是四篇文章 GAN ,CGAN, pix2pix和 cyclegan</p>
<p>主要还是看代码理解的，代码也加了一定量注释</p>
<h2 id="一gan">一、【GAN】</h2>
<p><strong>Paper:</strong> Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. &ldquo;Generative adversarial nets.&rdquo; <em>Advances in neural information processing systems</em> 27 (2014).</p>
<p><strong>remark</strong>：GAN的提出</p>
<p><strong>cited by</strong>： 34267</p>
<p><strong>code</strong>：https://github.com/eriklindernoren/PyTorch-GAN</p>
<h3 id="1-概要">1. 概要</h3>
<ol>
<li>提出了一个基于对抗的新生成式模型， 它由一个生成器和一个判别器组成</li>
<li>生成器的目标是学习到样本的数据分布， 从而能生成样本欺骗判别器； 判别器的目标是判断输入样本是生成/真实的概率。对于任意的生成器和判别器， 都存在一个独特的全局最优解</li>
<li>这篇文章中，生成器和判别器都由多层感知机实现</li>
</ol>
<p>判别式模型
• 模型学习的是条件概率分布P(Y|X)
• 任务是从属性X（特征） 预测标记Y（类别）
生成式模型
• 模型学习的是联合概率分布P(X,Y)
• 任务是得到属性为X且类别为Y时的联合概率</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831194741.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831194741.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831194741.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831194741.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831194741.png"
        title="gan" /></p>
<h3 id="2-基本架构">2. 基本架构</h3>
<blockquote>
<p>In this article, we explore the special case when the generative model generates samples
by passing random noise through a multilayer perceptron, and the discriminative model is also a
multilayer perceptron. We refer to this special case as adversarial nets.</p>
<p>In this case, we can train both models using only the highly successful backpropagation and dropout algorithms [16] and sample from the generative model using only forward propagation. No approximate inference or Markov chains are necessary</p>
</blockquote>
<p>随机噪声作为生成器的输入，模型是一个多层感知机的结构，判别器同样也是多层感知机。</p>
<h3 id="3-vae">3. VAE</h3>
<p>Variational Auto-Encoder</p>
<p>编码器把数据编码成mean vector和standard deviation vector</p>
<p>采样从构建的高斯分布中采样得到latent vector</p>
<p>解码器从latent vector生成数据</p>
<p>一个encoder-decoder的架构</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831101454.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831101454.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831101454.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831101454.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831101454.png"
        title="VAE" /></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">generation_loss</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">square</span><span class="p">(</span><span class="n">generated_image</span> <span class="o">-</span> <span class="n">real_image</span><span class="p">))</span> 

<span class="n">latent_loss</span> <span class="o">=</span><span class="n">KL</span><span class="o">-</span><span class="n">Divergence</span><span class="p">(</span><span class="n">latent_variable</span><span class="p">,</span><span class="n">unit_gaussian</span><span class="p">)</span> <span class="c1">#构造的高斯分布和单位高斯分布的KL散度</span>

<span class="n">loss</span><span class="o">=</span><span class="n">generation_loss</span> <span class="o">+</span><span class="n">latent_loss</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="4-gan">4. GAN</h3>
<p>生成器 G：多层感知机, ReLU, Sigmoid
判别器 D：多层感知机, Maxout, Dropout</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831102407.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831102407.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831102407.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831102407.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831102407.png"
        title="最初GAN" /></p>
<h3 id="5-value-function">5. Value function</h3>
<div>
$$
\min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}(\boldsymbol{x})}[\log D(\boldsymbol{x})]+\mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}(\boldsymbol{z})}[\log (1-D(G(\boldsymbol{z})))]
$$
<div/>
<p>data: 真实数据
D: 判别器， 输出值为 [0, 1]， 代表输入来自真实数据的概率
z: 随机噪声
G: 生成器， 输出为合成数据</p>
<p><strong>D的目标</strong>， 是最大化价值函数V
对数函数log在底数大于1时， 为单调递增函数
最大化V， 就是最大化 D(x) 和 1-D(G(z))
对于任意的x， 都有 D(x) = 1
对于任意的z， 都有 D(G(z))) = 0</p>
<p><strong>G的目标</strong>， 是针对特定的D， 去最小化价值函数V
最小化V， 就是最小化 D(x) 和 1-D(G(z))
对于任意的z， 都有 D(G(z))) = 1</p>
<h3 id="6-训练流程">6. 训练流程</h3>
<p>• 训练k次判别器（ 论文实验中k=1）
• 训练1次生成器</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831110722.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831110722.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831110722.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831110722.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831110722.png"
        title="训练过程" /></p>
<h3 id="7代码">7.代码</h3>
<p>生成器和判别器均为全连接层</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">def</span> <span class="nf">block</span><span class="p">(</span><span class="n">in_feat</span><span class="p">,</span> <span class="n">out_feat</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_feat</span><span class="p">,</span> <span class="n">out_feat</span><span class="p">)]</span>
            <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">out_feat</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">layers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">img_shape</span><span class="p">))),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">*</span><span class="n">img_shape</span><span class="p">)</span>  <span class="c1">#28*28</span>
        <span class="k">return</span> <span class="n">img</span>


<span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">img_shape</span><span class="p">)),</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>   <span class="c1">#0-1</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="n">img_flat</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">validity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">img_flat</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">validity</span>
</code></pre></td></tr></table>
</div>
</div><p>训练过程</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Loss function</span>
<span class="n">adversarial_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>  <span class="c1">#对抗损失以交叉熵损失的形式出现</span>

<span class="c1"># Initialize generator and discriminator</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">()</span>
<span class="n">discriminator</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span>

<span class="c1"># Configure data loader</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&#34;../../data/mnist&#34;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
        <span class="s2">&#34;../../data/mnist&#34;</span><span class="p">,</span>
        <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
            <span class="p">[</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">img_size</span><span class="p">),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">])]</span>
        <span class="p">),</span>
    <span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Optimizers，生成两个优化器，分别针对生成器和判别器的参数</span>
<span class="n">optimizer_G</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">b1</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">b2</span><span class="p">))</span>
<span class="n">optimizer_D</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">b1</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">b2</span><span class="p">))</span>

<span class="c1"># ----------</span>
<span class="c1">#  Training 开始训练</span>
<span class="c1"># ----------</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>

        <span class="c1"># Adversarial ground truths  对抗时候的GT, 这里1代表真，0代表假</span>
        <span class="n">valid</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># 1</span>
        <span class="n">fake</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>   <span class="c1"># 0</span>

        <span class="c1"># Configure input</span>
        <span class="n">real_imgs</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">Tensor</span><span class="p">))</span>    <span class="c1">##这个是真的图片</span>

        <span class="c1"># -----------------</span>
        <span class="c1">#  Train Generator    开始训练生成器（目的是使得生成的图片能以假乱真）</span>
        <span class="c1"># -----------------</span>

        <span class="n">optimizer_G</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Sample noise as generator input</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">opt</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">))))</span>  <span class="c1">#生成随机向量作为输入</span>

        <span class="c1"># Generate a batch of images</span>
        <span class="n">gen_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>  <span class="c1">##随机向量进入生成器  1*100 --&gt; 1*5xx  _&gt; 28*28</span>

        <span class="c1"># Loss measures generator&#39;s ability to fool the discriminator</span>
        <span class="n">g_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">),</span> <span class="n">valid</span><span class="p">)</span>  <span class="c1"># 希望能误导判别器，使得判别器认为该图是真</span>

        <span class="n">g_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>    <span class="c1">##反向传播</span>
        <span class="n">optimizer_G</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># ---------------------</span>
        <span class="c1">#  Train Discriminator  开始训练判别器（目的是希望能正确判断真假图片）</span>
        <span class="c1"># ---------------------</span>

        <span class="n">optimizer_D</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Measure discriminator&#39;s ability to classify real from generated samples</span>
        <span class="n">real_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">),</span> <span class="n">valid</span><span class="p">)</span> <span class="c1">#对于一张本来就是真的图片希望他能判断为真</span>
        <span class="n">fake_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="o">.</span><span class="n">detach</span><span class="p">()),</span> <span class="n">fake</span><span class="p">)</span> <span class="c1">#对于一张假的图片希望他能判断为假</span>
        <span class="n">d_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">real_loss</span> <span class="o">+</span> <span class="n">fake_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="n">d_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer_D</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008151729538.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008151729538.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008151729538.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008151729538.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008151729538.png"
        title="代码任务示意图" /></p>
<h2 id="二cgan">二、【CGAN】</h2>
<p><strong>Paper:</strong> Mirza, Mehdi, and Simon Osindero. &ldquo;Conditional generative adversarial nets.&rdquo; <em>arXiv preprint arXiv:1411.1784</em> (2014).</p>
<p><strong>remark</strong>：Conditional GAN,  可以生成指定条件下的图像</p>
<p><strong>cited by</strong>： 5877</p>
<p><strong>code</strong>：https://github.com/caffeinism/cDC-GAN-pytorch</p>
<h3 id="1-概要-1">1. 概要</h3>
<p>在原模型基础上，会输入额外的数据作为条件，对生成器和判别器都进行了修改。例如，在MNIST数据集上， 新模型可以生成以数字类别标签为条件的手写数字图像，模型还可以用来做多模态学习，可以生成输入图像相关的描述标签 。</p>
<h3 id="2多模态学习和图像描述">2.多模态学习和图像描述</h3>
<p><strong>多模态学习</strong>：</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831213316.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831213316.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831213316.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831213316.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831213316.png"
        title="多模态学习" /></p>
<p><strong>图像标记</strong>： 用词语对图像中不同内容进行多维度表述
<strong>图像描述</strong>： 把一幅图片翻译为一段描述文字，获取图像的标记词语，理解图像标记之间的关系，生成人类可读的句子</p>
<h3 id="3-网络结构">3. 网络结构</h3>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831201826.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831201826.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831201826.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831201826.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831201826.png"
        title="CGAN" /></p>
<p>与原始GAN不同的一点就在于，加入了Y，作为一个条件输入，在生成器和判别器中的y是同一个y。这里是嵌入后concat到一起。</p>
<p><strong>GAN的价值函数：</strong></p>
<div>
$$
\min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}(\boldsymbol{x})}[\log D(\boldsymbol{x})]+\mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}(\boldsymbol{z})}[\log (1-D(G(\boldsymbol{z})))]
$$
<div/>
<p><strong>CGAN的价值函数：</strong></p>
<div>
$$
\min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}(\boldsymbol{x})}[\log D(\boldsymbol{x} \mid \boldsymbol{y})]+\mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}(\boldsymbol{z})}[\log (1-D(G(\boldsymbol{z} \mid \boldsymbol{y})))]
$$
<div/>
<p>两者主要的区别就在于有一个条件的形式：x|y</p>
<h3 id="4-实验">4. 实验</h3>
<h4 id="单模态任务手写数字识别">单模态任务【手写数字识别】</h4>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831210636.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831210636.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831210636.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831210636.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831210636.png"
        title="单模态任务" /></p>
<p>y一个十维的向量，代表了数字0-9，它作为条件信息输入生成器和判别器。</p>
<p>训练复杂：采用随机梯度下降，使用初始值为0.5的初始动量， 并逐渐增加到0.7。在生成器和判别器上都使用概率为0.5的Dropout。 使用验证集上的最大对数似然估计作为停止点  。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831215954.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831215954.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831215954.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831215954.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831215954.png"
        title="CGAN中的生成器和判别器" /></p>
<h4 id="多模态任务有图像有文本">多模态任务【有图像有文本】</h4>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831213954.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831213954.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831213954.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831213954.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831213954.png"
        title="多模态任务" /></p>
<p>左边是在ImageNet上训练一个类似AlexNet的图像分类模型， 使用其最后一个全连接层的输出来提取图像特征。
右边是使用YFCC100M数据集， 训练一个词向量长度为200的 skip-gram模型（word2vector）。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831214212.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831214212.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831214212.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831214212.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831214212.png"
        title="多模态任务" /></p>
<p>基于MIR Flickr 25,000数据集， 使用上面的图像特征提取模型和skip-gram模型分别提取图像和标签特征。把提取的图像作为条件输入， 标签特征作为输出来训练CGAN。在训练CGAN时，不修改图像特征提取模型和skip-gram模型。在训练集内具有多个标签的图像， 每个标签训练一次。为每个条件输入生成100个样本， 对于每个样本输出的词向量，找到距离最近的20个单词。 在100*20个单词中，选择前10个最常见的单词 。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831214622.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831214622.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831214622.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831214622.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210831214622.png"
        title="生成器和判别器" /></p>
<h3 id="5代码">5.代码</h3>
<p>生成器和判别器也都是多层感知机，区别在于需要concat一个条件信息</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">label_emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">n_classes</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">block</span><span class="p">(</span><span class="n">in_feat</span><span class="p">,</span> <span class="n">out_feat</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_feat</span><span class="p">,</span> <span class="n">out_feat</span><span class="p">)]</span>
            <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">out_feat</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">layers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">+</span> <span class="n">opt</span><span class="o">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="o">*</span><span class="n">block</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">img_shape</span><span class="p">))),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>  <span class="c1"># 1x100 1x1(0-9)</span>
        <span class="c1"># Concatenate label embedding and image to produce input  1x10</span>
        <span class="n">gen_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">label_emb</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="n">noise</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1">#64*100 emb 64  -&gt; 64*110</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">gen_input</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">*</span><span class="n">img_shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span>


<span class="k">class</span> <span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Discriminator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">label_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">n_classes</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">n_classes</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">img_shape</span><span class="p">)),</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="c1"># Concatenate label embedding and image to produce input</span>
        <span class="n">d_in</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_embedding</span><span class="p">(</span><span class="n">labels</span><span class="p">)),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">validity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">d_in</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">validity</span>
</code></pre></td></tr></table>
</div>
</div><p>训练过程</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span><span class="lnt">87
</span><span class="lnt">88
</span><span class="lnt">89
</span><span class="lnt">90
</span><span class="lnt">91
</span><span class="lnt">92
</span><span class="lnt">93
</span><span class="lnt">94
</span><span class="lnt">95
</span><span class="lnt">96
</span><span class="lnt">97
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Loss functions</span>
<span class="n">adversarial_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="c1"># Initialize generator and discriminator</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">()</span>
<span class="n">discriminator</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">()</span>


<span class="c1"># Configure data loader</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&#34;../../data/mnist&#34;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
        <span class="s2">&#34;../../data/mnist&#34;</span><span class="p">,</span>
        <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
            <span class="p">[</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">img_size</span><span class="p">),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">])]</span>
        <span class="p">),</span>
    <span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Optimizers</span>
<span class="n">optimizer_G</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">b1</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">b2</span><span class="p">))</span>
<span class="n">optimizer_D</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">discriminator</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">b1</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">b2</span><span class="p">))</span>



<span class="k">def</span> <span class="nf">sample_image</span><span class="p">(</span><span class="n">n_row</span><span class="p">,</span> <span class="n">batches_done</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;Saves a grid of generated digits ranging from 0 to n_classes&#34;&#34;&#34;</span>
    <span class="c1"># Sample noise</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">n_row</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">))))</span>
    <span class="c1"># Get labels ranging from 0 to n_classes for n rows</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">num</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_row</span><span class="p">)</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_row</span><span class="p">)])</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
    <span class="n">gen_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">save_image</span><span class="p">(</span><span class="n">gen_imgs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="s2">&#34;images/</span><span class="si">%d</span><span class="s2">.png&#34;</span> <span class="o">%</span> <span class="n">batches_done</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="n">n_row</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="c1"># ----------</span>
<span class="c1">#  Training</span>
<span class="c1"># ----------</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Adversarial ground truths</span>
        <span class="n">valid</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">fake</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Configure input</span>
        <span class="n">real_imgs</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">imgs</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">FloatTensor</span><span class="p">))</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">LongTensor</span><span class="p">))</span>   <span class="c1">#是数字，代表上面的img是什么数字</span>

        <span class="c1"># -----------------</span>
        <span class="c1">#  Train Generator</span>
        <span class="c1"># -----------------</span>

        <span class="n">optimizer_G</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Sample noise and labels as generator input  生成随机向量和条件作为输入</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">))))</span>   <span class="c1">#64*100</span>
        <span class="n">gen_labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)))</span>   <span class="c1">#64</span>
       

        <span class="c1"># Generate a batch of images</span>
        <span class="n">gen_imgs</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">gen_labels</span><span class="p">)</span>  <span class="c1">#64*1*32*32</span>

        <span class="c1"># Loss measures generator&#39;s ability to fool the discriminator</span>
        <span class="n">validity</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="p">,</span> <span class="n">gen_labels</span><span class="p">)</span>  <span class="c1"># 64*1</span>
        <span class="n">g_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">validity</span><span class="p">,</span> <span class="n">valid</span><span class="p">)</span>  <span class="c1">##希望是真</span>

        <span class="n">g_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer_G</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># ---------------------</span>
        <span class="c1">#  Train Discriminator</span>
        <span class="c1"># ---------------------</span>

        <span class="n">optimizer_D</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Loss for real images</span>
        <span class="n">validity_real</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">real_imgs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">d_real_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">validity_real</span><span class="p">,</span> <span class="n">valid</span><span class="p">)</span>

        <span class="c1"># Loss for fake images</span>
        <span class="n">validity_fake</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">gen_imgs</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">gen_labels</span><span class="p">)</span>
        <span class="n">d_fake_loss</span> <span class="o">=</span> <span class="n">adversarial_loss</span><span class="p">(</span><span class="n">validity_fake</span><span class="p">,</span> <span class="n">fake</span><span class="p">)</span>

        <span class="c1"># Total discriminator loss</span>
        <span class="n">d_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">d_real_loss</span> <span class="o">+</span> <span class="n">d_fake_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="n">d_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer_D</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008151906105.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008151906105.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008151906105.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008151906105.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008151906105.png"
        title="CGAN生成效果" /></p>
<h2 id="三pix2pix">三、【pix2pix】</h2>
<p><strong>Paper:</strong> Isola, Phillip, Jun-Yan Zhu, Tinghui Zhou, and Alexei A. Efros. &ldquo;Image-to-image translation with conditional adversarial networks.&rdquo; In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pp. 1125-1134. 2017.</p>
<p><strong>remark</strong>：图像翻译</p>
<p><strong>cited by</strong>： 10095</p>
<p><strong>code</strong>：https://phillipi.github.io/pix2pix/?utm_source=catalyzex.com</p>
<h3 id="1-概要-2">1. 概要</h3>
<p>研究条件生成式对抗网络在图像翻译任务中的通用解决方案。网络不仅学习从输入图像到输出图像的映射（生成器），还学习了用于训练该映射的损失函数（判别器）。把这种方法可以有效应用在图像合成，图像上色等多种图像翻译任务中。表明可以在不手工设计损失函数的情况下，也能获得理想的结果。</p>
<h3 id="2-网络结构">2. 网络结构</h3>
<p><strong>生成器</strong>是一个UNet。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210901152037.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210901152037.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210901152037.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210901152037.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210901152037.png"
        title="unet" /></p>
<p><strong>判别器</strong>是PatchGAN</p>
<p>作者认为像素级的l1 loss能很好的捕捉到图像中的低频信息，GAN的判别器只需要关注高频信息。所以把图像切成 N*N 的patch，其中N显著小于图像尺寸。假设在大于N时，像素之间是相互独立的，从而可以把图像建模成马尔科夫随机场。把判别器在所有patch上的推断结果，求平均来作为最终输出。可以把PatchGAN理解为对图像纹理/style损失的计算。</p>
<p><strong>目标函数</strong></p>
<p>总的目标是:</p>
<div>
$$
G^{*}=\arg \min _{G} \max _{D} {L}_{c G A N}(G, D)+\lambda {L}_{L 1}(G) .
$$
<div/>
<p>它由一个cgan损失和L1损失加权相加而成。其中cgan的损失为：</p>
<div>
$$
\begin{aligned}
\mathcal{L}_{c G A N}(G, D)=& \mathbb{E}_{x, y}[\log D(x, y)]+\mathbb{E}_{x, z}[\log (1-D(x, G(x, z))]
\end{aligned}
$$
<div/>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210901161742.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210901161742.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210901161742.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210901161742.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210901161742.png"
        title="pix2pix" /></p>
<p>这里的x是条件，也就是一个分割图。y是通过生成器生成的实景图。在判别器中，y可以是前面生成器的输出，也可以是GT。patchgan的体现就是，最后输出时，(16,16,1)中的每一个像素点，都代表着原图中的一个16x16的patch。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">criterion_GAN</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">criterion_pixelwise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>

        <span class="c1"># Model inputs</span>
        <span class="n">real_A</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&#34;B&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">Tensor</span><span class="p">))</span>   <span class="c1">#真实的分割图 1*3*256*256</span>
        <span class="n">real_B</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&#34;A&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">Tensor</span><span class="p">))</span>   <span class="c1">#真实的建筑图 1*3*256*256</span>

        <span class="c1"># Adversarial ground truths</span>
        <span class="n">valid</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">real_A</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">*</span><span class="n">patch</span><span class="p">))),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1">#全1(1*1*16*16)</span>
        <span class="n">fake</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">real_A</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">*</span><span class="n">patch</span><span class="p">))),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1">#全0(1*1*16*16)</span>

        <span class="c1"># ------------------</span>
        <span class="c1">#  Train Generators</span>
        <span class="c1"># ------------------</span>

        <span class="n">optimizer_G</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># GAN loss</span>
        <span class="n">fake_B</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">real_A</span><span class="p">)</span>   <span class="c1">#先通过真的分割图生成假的建筑图 1*3*256*256</span>
        <span class="n">pred_fake</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">fake_B</span><span class="p">,</span> <span class="n">real_A</span><span class="p">)</span>  <span class="c1">#判别一个这个假的建筑图 1*1*16*16</span>
        <span class="n">loss_GAN</span> <span class="o">=</span> <span class="n">criterion_GAN</span><span class="p">(</span><span class="n">pred_fake</span><span class="p">,</span> <span class="n">valid</span><span class="p">)</span> <span class="c1">#希望被判别器识别错误</span>
        <span class="c1"># Pixel-wise loss</span>
        <span class="n">loss_pixel</span> <span class="o">=</span> <span class="n">criterion_pixelwise</span><span class="p">(</span><span class="n">fake_B</span><span class="p">,</span> <span class="n">real_B</span><span class="p">)</span> <span class="c1">#计算与真实建筑图之间的差距 1*3*256*256</span>

        <span class="c1"># Total loss</span>
        <span class="n">loss_G</span> <span class="o">=</span> <span class="n">loss_GAN</span> <span class="o">+</span> <span class="n">lambda_pixel</span> <span class="o">*</span> <span class="n">loss_pixel</span> 

        <span class="n">loss_G</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="n">optimizer_G</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
      <span class="c1">#先训练生成器，对于生成器来讲，有两个损失GAN loss（由MSE实现）和Pixel-wise loss。其中GAN loss就是希望生成器生成的假图片逼近真的。Pixel-wise loss就是生成图和label的L1—loss。</span>


        <span class="c1"># ---------------------</span>
        <span class="c1">#  Train Discriminator</span>
        <span class="c1"># ---------------------</span>

        <span class="n">optimizer_D</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Real loss</span>
        <span class="n">pred_real</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">real_B</span><span class="p">,</span> <span class="n">real_A</span><span class="p">)</span>
        <span class="n">loss_real</span> <span class="o">=</span> <span class="n">criterion_GAN</span><span class="p">(</span><span class="n">pred_real</span><span class="p">,</span> <span class="n">valid</span><span class="p">)</span>

        <span class="c1"># Fake loss</span>
        <span class="n">pred_fake</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">fake_B</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">real_A</span><span class="p">)</span>
        <span class="n">loss_fake</span> <span class="o">=</span> <span class="n">criterion_GAN</span><span class="p">(</span><span class="n">pred_fake</span><span class="p">,</span> <span class="n">fake</span><span class="p">)</span>

        <span class="c1"># Total loss</span>
        <span class="n">loss_D</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">loss_real</span> <span class="o">+</span> <span class="n">loss_fake</span><span class="p">)</span>

        <span class="n">loss_D</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer_D</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
   <span class="c1">##对于判别器来讲，一方面希望能将真实的图片识别为真。另外一方面，希望将假的图片识别为假，两个平均求和</span>


        <span class="c1"># --------------</span>
        <span class="c1">#  Log Progress</span>
        <span class="c1"># --------------</span>

        <span class="c1"># Determine approximate time left</span>
        <span class="n">batches_done</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span> <span class="o">+</span> <span class="n">i</span>
        <span class="n">batches_left</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">n_epochs</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span> <span class="o">-</span> <span class="n">batches_done</span>
        <span class="n">time_left</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="n">batches_left</span> <span class="o">*</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">prev_time</span><span class="p">))</span>
        <span class="n">prev_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

</code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008152002595.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008152002595.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008152002595.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008152002595.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008152002595.png"
        title="p2p的生成示意图" /></p>
<h2 id="四cyclegan">四、【CycleGAN】</h2>
<p><strong>Paper:</strong> Zhu, Jun-Yan, Taesung Park, Phillip Isola, and Alexei A. Efros. &ldquo;Unpaired image-to-image translation using cycle-consistent adversarial networks.&rdquo; In <em>Proceedings of the IEEE international conference on computer vision</em>, pp. 2223-2232. 2017.</p>
<p><strong>remark</strong>：图像翻译 无监督 Domain Adaptation</p>
<p><strong>cited by</strong>： 9546</p>
<p><strong>code</strong>：https://github.com/junyanz/CycleGAN</p>
<h3 id="1-概要-3">1. 概要</h3>
<p>一般来说，图像翻译任务需要对齐的图像对， 但很多场景下无法获得这样的训练数据。于是作者提出了一个基于非配对数据的方法， 可以学习到不同 domain 图像间的映射。CycleGAN是在GAN loss的基础上加入循环一致性损失，使得 F(G(X)) 尽量接近X（反之亦然）。</p>
<h3 id="2-网络结构和设计框架">2. 网络结构和设计框架</h3>
<p><strong>生成器</strong></p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210902113043.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210902113043.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210902113043.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210902113043.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210902113043.png"
        title="cyclegan生成器" /></p>
<p><strong>判别器</strong></p>
<p>判别器使用了PatchGAN</p>
<p><strong>架构</strong></p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210902134120.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210902134120.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210902134120.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210902134120.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210902134120.png"
        title="cyclegan" /></p>
<h3 id="3-损失函数">3. 损失函数</h3>
<p>目标是在X和Y两个不同domain间，建立起双向的映射关系 G 和 F ；并使用两个判别器$D_X$和$D_Y$，来分别对{x}和{F(Y)}、{y}和{G(x)}进行区分，于是就存在两个损失：
• 对抗损失——使得映射后的数据分布接近目标domain的数据分布
• 循环一致性损失——保证学习到的两个映射 G 和 F 不会相互矛盾</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210902110931.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210902110931.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210902110931.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210902110931.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20210902110931.png"
        title="cyclegan" /></p>
<p>GAN损失使用的是和传统GAN网络一致的对抗损失函数</p>
<div>
$$
\begin{aligned}
\mathcal{L}_{\mathrm{GAN}}\left(G, D_{Y}, X, Y\right) &=\mathbb{E}_{y \sim p_{\text {atat }}(y)}\left[\log D_{Y}(y)\right] \\
&+\mathbb{E}_{x \sim p_{\text {data }}(x)}\left[\log \left(1-D_{Y}(G(x))\right]\right.
\end{aligned}
$$
<div/>
<p>优化目标是两个min-max函数</p>
<div>
$$
\begin{aligned}
&\min _{G} \max _{D_{Y}} \mathcal{L}_{\mathrm{GAN}}\left(G, D_{Y}, X, Y\right) \\
&\min _{F} \max _{D_{X}} \mathcal{L}_{\mathrm{GAN}}\left(F, D_{X}, Y, X\right)
\end{aligned}
$$
<div/>
循环一致性损失 ，对于任意一个x和y， 应该有：  
<div>
$$
\begin{aligned}
&x \rightarrow G(x) \rightarrow F(G(x)) \approx x \\
&y \rightarrow F(y) \rightarrow G(F(y)) \approx y
\end{aligned}
$$
<div/>
使用L1距离时， 则损失函数为：  
<div>
$$
\begin{aligned}
\mathcal{L}_{\text {cyc }}(G, F) &=\mathbb{E}_{x \sim p_{\text {data }}(x)}\left[\|F(G(x))-x\|_{1}\right] \\
&+\mathbb{E}_{y \sim p_{\text {data }}(y)}\left[\|G(F(y))-y\|_{1}\right]
\end{aligned}
$$
<div/>
于是，完整的损失函数应该为：
<div>
$$
\begin{aligned}
\mathcal{L}\left(G, F, D_{X}, D_{Y}\right) &=\mathcal{L}_{\mathrm{GAN}}\left(G, D_{Y}, X, Y\right) \\
&+\mathcal{L}_{\mathrm{GAN}}\left(F, D_{X}, Y, X\right) \\
&+\lambda \mathcal{L}_{\text {cyc }}(G, F)
\end{aligned}
$$
<div/>
论文里没有提，但是代码中还存在的一个损失，identity损失：
<div>
$$
\begin{aligned}
\mathcal{L}_{\text {identity }}(G, F)=\mathbb{E}_{y \sim p_{\text {data }}(y)}\left[\|G(y)-y\|_{1}\right]+
&\mathbb{E}_{x \sim p_{\text {data }}(x)}\left[\|F(x)-x\|_{1}\right]
\end{aligned}
$$
<div/>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1">#先定义损失函数：</span>
<span class="n">criterion_GAN</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>   <span class="c1">##判别器损失</span>
<span class="n">criterion_cycle</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()</span>  <span class="c1">##循环一致性损失</span>
<span class="n">criterion_identity</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()</span>  <span class="c1">##identity损失</span>

<span class="c1">#两个生成器</span>
<span class="n">G_AB</span> <span class="o">=</span> <span class="n">GeneratorResNet</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">n_residual_blocks</span><span class="p">)</span>
<span class="n">G_BA</span> <span class="o">=</span> <span class="n">GeneratorResNet</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">n_residual_blocks</span><span class="p">)</span>

<span class="c1">#两个判别器</span>
<span class="n">D_A</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
<span class="n">D_B</span> <span class="o">=</span> <span class="n">Discriminator</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

<span class="c1">##定义优化器</span>
<span class="n">optimizer_G</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
    <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="n">G_AB</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">G_BA</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span> <span class="n">lr</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">b1</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">b2</span><span class="p">)</span>
<span class="p">)</span> 

<span class="n">optimizer_D_A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">D_A</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">b1</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">b2</span><span class="p">))</span>
<span class="n">optimizer_D_B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">D_B</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">b1</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">b2</span><span class="p">))</span>


<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>

        <span class="c1"># Set model input </span>
        <span class="n">real_A</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&#34;A&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">Tensor</span><span class="p">))</span>  <span class="c1"># A是油画图   1*3*256*256</span>
        <span class="n">real_B</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&#34;B&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">Tensor</span><span class="p">))</span>  <span class="c1"># B是真实的风景图  1*3*256*256</span>

        <span class="c1"># Adversarial ground truths</span>
        <span class="n">valid</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">real_A</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">*</span><span class="n">D_A</span><span class="o">.</span><span class="n">output_shape</span><span class="p">))),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="c1">#表真</span>
        <span class="c1">#1*1*16*16</span>
        <span class="n">fake</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">real_A</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">*</span><span class="n">D_A</span><span class="o">.</span><span class="n">output_shape</span><span class="p">))),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="c1">#表假</span>

        <span class="c1"># ------------------</span>
        <span class="c1">#  Train Generators</span>
        <span class="c1"># ------------------</span>
        <span class="c1">##训练生成器：</span>

        <span class="n">G_AB</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">G_BA</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="n">optimizer_G</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  <span class="c1">#生成器的优化器</span>

        <span class="c1"># Identity loss</span>
        <span class="n">loss_id_A</span> <span class="o">=</span> <span class="n">criterion_identity</span><span class="p">(</span><span class="n">G_BA</span><span class="p">(</span><span class="n">real_A</span><span class="p">),</span> <span class="n">real_A</span><span class="p">)</span> <span class="c1">#通过BA生成器后的输出和自身的损失，不要偏离太远 </span>
        <span class="n">loss_id_B</span> <span class="o">=</span> <span class="n">criterion_identity</span><span class="p">(</span><span class="n">G_AB</span><span class="p">(</span><span class="n">real_B</span><span class="p">),</span> <span class="n">real_B</span><span class="p">)</span>     <span class="c1"># 1*3*256*256</span>

        <span class="n">loss_identity</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss_id_A</span> <span class="o">+</span> <span class="n">loss_id_B</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="c1"># GAN loss</span>
        <span class="n">fake_B</span> <span class="o">=</span> <span class="n">G_AB</span><span class="p">(</span><span class="n">real_A</span><span class="p">)</span>   <span class="c1"># 1*3*256*256</span>
        <span class="n">loss_GAN_AB</span> <span class="o">=</span> <span class="n">criterion_GAN</span><span class="p">(</span><span class="n">D_B</span><span class="p">(</span><span class="n">fake_B</span><span class="p">),</span> <span class="n">valid</span><span class="p">)</span> <span class="c1">#对于生成器来讲，希望生成的假图被判别器判断为真。		                                                           D_B(fake_B)的结果是1*1*16*16</span>
        <span class="n">fake_A</span> <span class="o">=</span> <span class="n">G_BA</span><span class="p">(</span><span class="n">real_B</span><span class="p">)</span>
        <span class="n">loss_GAN_BA</span> <span class="o">=</span> <span class="n">criterion_GAN</span><span class="p">(</span><span class="n">D_A</span><span class="p">(</span><span class="n">fake_A</span><span class="p">),</span> <span class="n">valid</span><span class="p">)</span>  <span class="c1">#A到B，B到A各来一次</span>

        <span class="n">loss_GAN</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss_GAN_AB</span> <span class="o">+</span> <span class="n">loss_GAN_BA</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="c1"># Cycle loss</span>
        <span class="n">recov_A</span> <span class="o">=</span> <span class="n">G_BA</span><span class="p">(</span><span class="n">fake_B</span><span class="p">)</span> <span class="c1"># 1*3*256*256</span>
        <span class="n">loss_cycle_A</span> <span class="o">=</span> <span class="n">criterion_cycle</span><span class="p">(</span><span class="n">recov_A</span><span class="p">,</span> <span class="n">real_A</span><span class="p">)</span> <span class="c1">#生成的假图再从B-&gt;A，得到循环一致性损失</span>
        <span class="n">recov_B</span> <span class="o">=</span> <span class="n">G_AB</span><span class="p">(</span><span class="n">fake_A</span><span class="p">)</span>
        <span class="n">loss_cycle_B</span> <span class="o">=</span> <span class="n">criterion_cycle</span><span class="p">(</span><span class="n">recov_B</span><span class="p">,</span> <span class="n">real_B</span><span class="p">)</span>

        <span class="n">loss_cycle</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss_cycle_A</span> <span class="o">+</span> <span class="n">loss_cycle_B</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="c1"># Total loss</span>
        <span class="n">loss_G</span> <span class="o">=</span> <span class="n">loss_GAN</span> <span class="o">+</span> <span class="n">opt</span><span class="o">.</span><span class="n">lambda_cyc</span> <span class="o">*</span> <span class="n">loss_cycle</span> <span class="o">+</span> <span class="n">opt</span><span class="o">.</span><span class="n">lambda_id</span> <span class="o">*</span> <span class="n">loss_identity</span>

        <span class="n">loss_G</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1">###同时优化两个生成器</span>
        <span class="n">optimizer_G</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="c1">##训练判别器A：</span>
		<span class="c1">#两个判别器是分开来训练更新的</span>

        <span class="c1"># -----------------------</span>
        <span class="c1">#  Train Discriminator A</span>
        <span class="c1"># -----------------------</span>

        <span class="n">optimizer_D_A</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Real loss</span>
        <span class="n">loss_real</span> <span class="o">=</span> <span class="n">criterion_GAN</span><span class="p">(</span><span class="n">D_A</span><span class="p">(</span><span class="n">real_A</span><span class="p">),</span> <span class="n">valid</span><span class="p">)</span>  <span class="c1">#1*1*16*16</span>
        <span class="c1"># Fake loss (on batch of previously generated samples)</span>
        <span class="n">fake_A_</span> <span class="o">=</span> <span class="n">fake_A_buffer</span><span class="o">.</span><span class="n">push_and_pop</span><span class="p">(</span><span class="n">fake_A</span><span class="p">)</span>
        <span class="n">loss_fake</span> <span class="o">=</span> <span class="n">criterion_GAN</span><span class="p">(</span><span class="n">D_A</span><span class="p">(</span><span class="n">fake_A_</span><span class="o">.</span><span class="n">detach</span><span class="p">()),</span> <span class="n">fake</span><span class="p">)</span>
        <span class="c1"># Total loss</span>
        <span class="n">loss_D_A</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss_real</span> <span class="o">+</span> <span class="n">loss_fake</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="n">loss_D_A</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer_D_A</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># -----------------------</span>
        <span class="c1">#  Train Discriminator B</span>
        <span class="c1"># -----------------------</span>

        <span class="c1">##同理训练判别器B：</span>
        <span class="n">optimizer_D_B</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Real loss</span>
        <span class="n">loss_real</span> <span class="o">=</span> <span class="n">criterion_GAN</span><span class="p">(</span><span class="n">D_B</span><span class="p">(</span><span class="n">real_B</span><span class="p">),</span> <span class="n">valid</span><span class="p">)</span>    <span class="c1">#判别器希望能把对的认对</span>
        <span class="c1"># Fake loss (on batch of previously generated samples)</span>
        <span class="n">fake_B_</span> <span class="o">=</span> <span class="n">fake_B_buffer</span><span class="o">.</span><span class="n">push_and_pop</span><span class="p">(</span><span class="n">fake_B</span><span class="p">)</span>
        <span class="n">loss_fake</span> <span class="o">=</span> <span class="n">criterion_GAN</span><span class="p">(</span><span class="n">D_B</span><span class="p">(</span><span class="n">fake_B_</span><span class="o">.</span><span class="n">detach</span><span class="p">()),</span> <span class="n">fake</span><span class="p">)</span> <span class="c1">#判别器希望吧错的辨别出来</span>
        <span class="c1"># Total loss</span>
        <span class="n">loss_D_B</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss_real</span> <span class="o">+</span> <span class="n">loss_fake</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="n">loss_D_B</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer_D_B</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">loss_D</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss_D_A</span> <span class="o">+</span> <span class="n">loss_D_B</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
</code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008152121452.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008152121452.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008152121452.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008152121452.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20211008152121452.png"
        title="cyclegan任务示意图" /></p></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2020-11-02</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="http://www.jqc8438.top/2021/11/gan/" data-title="【论文笔记】GAN基础与代码解读（GAN、CGAN、pix2pix、CycleGAN）" data-hashtags="GAN,生成对抗网络"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="http://www.jqc8438.top/2021/11/gan/" data-hashtag="GAN"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="http://www.jqc8438.top/2021/11/gan/" data-title="【论文笔记】GAN基础与代码解读（GAN、CGAN、pix2pix、CycleGAN）" data-image="/images/GAN.jpg"><i class="fab fa-weibo fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Blogger" data-sharer="blogger" data-url="http://www.jqc8438.top/2021/11/gan/" data-title="【论文笔记】GAN基础与代码解读（GAN、CGAN、pix2pix、CycleGAN）" data-description="（GAN、CGAN、pix2pix、CycleGAN）"><i class="fab fa-blogger fa-fw"></i></a><a href="javascript:void(0);" title="分享到 百度" data-sharer="baidu" data-url="http://www.jqc8438.top/2021/11/gan/" data-title="【论文笔记】GAN基础与代码解读（GAN、CGAN、pix2pix、CycleGAN）"><i data-svg-src="/lib/simple-icons/icons/baidu.min.svg"></i></a><a href="javascript:void(0);" title="分享到 Evernote" data-sharer="evernote" data-url="http://www.jqc8438.top/2021/11/gan/" data-title="【论文笔记】GAN基础与代码解读（GAN、CGAN、pix2pix、CycleGAN）"><i class="fab fa-evernote fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/gan/">GAN</a>,&nbsp;<a href="/tags/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/">生成对抗网络</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/2021/10/lvm/" class="prev" rel="prev" title="【Linux学习】Linux-LVM"><i class="fas fa-angle-left fa-fw"></i>【Linux学习】Linux-LVM</a>
            <a href="/2021/11/miniconda/" class="next" rel="next" title="【环境配置】Miniconda-不设环境变量/北外源">【环境配置】Miniconda-不设环境变量/北外源<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">由 <a href="https://gohugo.io/" target="_blank" rel="noopener noreferrer" title="Hugo 0.89.4">Hugo</a> 驱动 | 主题 - <a href="https://github.com/sunt-programator/CodeIT" target="_blank" rel="noopener noreferrer" title="CodeIT 0.2.10"><i class="fas fa-laptop-code fa-fw"></i> CodeIT</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2020 - 2021</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank" rel="noopener noreferrer">jinhaha</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript" src="/lib/cookieconsent/cookieconsent.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":10},"comment":{},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
