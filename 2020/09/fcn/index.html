<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>【论文笔记】FCN - 金哈哈的博客</title><meta name="description" content="Fully Convolutional Networks for Semantic Segmentation "><meta property="og:title" content="【论文笔记】FCN" />
<meta property="og:description" content="Fully Convolutional Networks for Semantic Segmentation " />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://jqc8438.github.io/2020/09/fcn/" /><meta property="og:image" content="http://jqc8438.github.io/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-09-27T14:09:10+08:00" />
<meta property="article:modified_time" content="2020-09-27T14:09:10+08:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="http://jqc8438.github.io/logo.png"/>

<meta name="twitter:title" content="【论文笔记】FCN"/>
<meta name="twitter:description" content="Fully Convolutional Networks for Semantic Segmentation "/>
<meta name="application-name" content="jinhaha">
<meta name="apple-mobile-web-app-title" content="jinhaha"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://jqc8438.github.io/2020/09/fcn/" /><link rel="prev" href="http://jqc8438.github.io/2020/09/deeplabv3p/" /><link rel="next" href="http://jqc8438.github.io/2020/11/hrnet/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "【论文笔记】FCN",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/jqc8438.github.io\/2020\/09\/fcn\/"
        },"genre": "posts","keywords": "语义分割","wordcount":  1614 ,
        "url": "http:\/\/jqc8438.github.io\/2020\/09\/fcn\/","datePublished": "2020-09-27T14:09:10+08:00","dateModified": "2020-09-27T14:09:10+08:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "jinhaha"
            },"description": "Fully Convolutional Networks for Semantic Segmentation "
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">('true' === 'true' && window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="金哈哈的博客"><span class="header-title-pre"><i class='fas fa-laptop-code fa-fw'></i></span>金哈哈的blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 归档 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/about/"> 关于 </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="金哈哈的博客"><span class="header-title-pre"><i class='fas fa-laptop-code fa-fw'></i></span>金哈哈的blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">归档</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/about/" title="">关于</a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">【论文笔记】FCN</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>jinhaha</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><i class="far fa-folder fa-fw"></i>论文笔记</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2020-09-27">2020-09-27</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 1614 字&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 4 分钟&nbsp;</div>
        </div><div class="featured-image"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="/images/FCN.png"
        data-srcset="/images/FCN.png, /images/FCN.png 1.5x, /images/FCN.png 2x"
        data-sizes="auto"
        alt="/images/FCN.png"
        title="Fully Convolutional Networks for Semantic Segmentation " /></div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#主要思路和特定">主要思路和特定</a></li>
    <li><a href="#对传统cnn网络的改变">对传统cnn网络的改变</a></li>
    <li><a href="#网络结构">网络结构</a></li>
    <li><a href="#上采样-反卷积">上采样-反卷积</a></li>
    <li><a href="#skip结构">skip结构</a></li>
    <li><a href="#conclusion">Conclusion</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p><strong>原文</strong>：Fully Convolutional Networks for Semantic Segmentation</p>
<p><strong>论文链接</strong>:</p>
<ul>
<li><a href="https://arxiv.org/abs/1411.4038" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/1411.4038</a></li>
<li><a href="https://arxiv.org/abs/1411.4038v2" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/1411.4038v2</a></li>
</ul>
<p><strong>Caffe 官方实现</strong>:https://github.com/shelhamer/fcn.berkeleyvision.org</p>
<p>**笔记时间：**2020.9.27</p>
<p><strong>可能存在的改进点（就当时而言）</strong>：</p>
<p>①拼接的方法不一定要点位相加，可以尝试像u-net一样的channel拼接。</p>
<p>②对类别之间关系进行联系，条件随机场。</p>
<h2 id="主要思路和特定">主要思路和特定</h2>
<p>1.使用全卷积（没有全连接层）的网络：改造AlexNet，the VGG ，GoogLeNet。文章和代码主要是对VGG进行改进。</p>
<p>2.输入的图像可以是任意尺寸的。</p>
<p>3.上采样使用了反卷积的技术</p>
<p>4.有skip结构，对信息进行了融合（融合的方式有直接逐点相加，通道中拼接。这里是用的直接逐点相加）</p>
<h2 id="对传统cnn网络的改变">对传统cnn网络的改变</h2>
<p>传统的cnn模型，卷积之后会展开成向量进行全连接网络，最后都是会输出一个向量，用来判别该图像属于某一类（是对图像层面上的一个分类）。而FCN全程都是卷积，最后通过上采样会得到一个与原图一样大的图，实现对每一个pixel的分类。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20200928100817231.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20200928100817231.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20200928100817231.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20200928100817231.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20200928100817231.png"
        title="CNN变FCN" /></p>
<p>从上图就可以看出CNN最后是要判断这个图是什么类的。而FCN想要给出具体像素的类别所属。</p>
<h2 id="网络结构">网络结构</h2>
<p>网络结构主要还是对AlexNet进行了一个改造，把最后两个全连接层改成了卷积层。</p>
<blockquote>
<p>其实在论文中，达到最好效果的网络是VGG16，此处可能使用AlexNet便于绘图。</p>
</blockquote>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20160508234037674.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20160508234037674.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20160508234037674.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20160508234037674.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20160508234037674.png"
        title="网络结构" /></p>
<p>蓝色块代表conv，绿色代表max pooling，灰色是裁剪，橙色是deconv，黄色是融合。</p>
<p>论文中也有提到，如果直接使用高维特征图进行上采样，得到的效果并不会很好。所以上采样的过程需要慢慢进行并融合低维度的特征图。例如上图所示，如果直接将16x16的最高维的图上采样变成500x500不会有好的结果。要先对16x16的特征图做一次&quot;小型的&quot;上次采样，得到34x34的图，再与前面的低维特征图进行一定的融合，再进行后面的操作。</p>
<p>模型最后的输出是21张变为原图大小的图片。为了对每个像素进行分类（看看这个像素属于21类中的哪一类），对逐个像素进行在不同分类上的概率值（就是该像素对应在21张图上的值）进行求解，最大的值便是该像素属于的分类。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20200928103814504.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20200928103814504.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20200928103814504.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20200928103814504.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/image-20200928103814504.png"
        title="示意图" /></p>
<h2 id="上采样-反卷积">上采样-反卷积</h2>
<p>上采样的方法一般有插值法、反卷积、反池化。本文使用的是反卷积。</p>
<p>反卷积（deconvolution）</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/4264437-1c13a9d9033d3594.webp"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/4264437-1c13a9d9033d3594.webp, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/4264437-1c13a9d9033d3594.webp 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/4264437-1c13a9d9033d3594.webp 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/4264437-1c13a9d9033d3594.webp"
        title="反卷积" /></p>
<p>对于上图来说，反卷积的输入是下面的部分，反卷积的输出是上面的部分。阴影部分是卷积核。</p>
<p>操作的基本流程就是先对输入先进行padding，在进行常规的卷积操作即可。关于反卷积的细节可以参考：</p>
<p><strong><a href="https://towardsdatascience.com/up-sampling-with-transposed-convolution-9ae4f2df52d0" target="_blank" rel="noopener noreferrer">《Up-sampling with Transposed Convolution》</a></strong></p>
<blockquote>
<p>关于转置卷积矩阵的参数随着训练过程不断被优化，但是它是在随机初始化的基础上进行优化，还是在原始卷积矩阵的基础上进行优化？</p>
<p>答：根据pytorch的源码，是随机生成的符合尺寸的就行。</p>
</blockquote>
<h2 id="skip结构">skip结构</h2>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20161022113219788.png"
        data-srcset="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20161022113219788.png, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20161022113219788.png 1.5x, https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20161022113219788.png 2x"
        data-sizes="auto"
        alt="https://jqc8438-pic.oss-cn-shanghai.aliyuncs.com/img/20161022113219788.png"
        title="skip" /></p>
<p>对原图进行卷积conv1、pool1后图像缩小为1/2；对图像进行第二次卷积conv2、pool2后图像缩小为1/4；对图像进行第三次卷积conv3、pool3后图像缩小为1/8，此时保留pool3的feature map3；对图像进行第四次卷积conv4、pool4后图像缩小为1/16，此时保留pool4的feature map4；对图像进行第五次卷积conv5、pool5后图像缩小为1/32，然后把原来CNN操作过程中的全连接改成卷积操作的conv6、conv7，图像的feature map5的大小依然为原图的1/32。将feature map5的上采样结果和feature map4进行融合，得到feature map4.5。再将feature map4.5的上采样结果feature map3进行融合得到1/8原始图像大小的图，将这个图进行8倍的上采样得到与原图一样像素大小的图。实现像素级分类的结果。</p>
<h2 id="conclusion">Conclusion</h2>
<blockquote>
<p>Fully convolutional networks are a rich class of models, of which modern classification convnets are a special case. Recognizing this, extending these classification  nets to segmentation, and improving the architecture with multi-resolution layer combinations dramatically improves the state-of-the-art, while simultaneously simplifying and speeding up learning and inference.</p>
</blockquote></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2020-09-27</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="http://jqc8438.github.io/2020/09/fcn/" data-title="【论文笔记】FCN" data-hashtags="语义分割"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="http://jqc8438.github.io/2020/09/fcn/" data-hashtag="语义分割"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="http://jqc8438.github.io/2020/09/fcn/" data-title="【论文笔记】FCN" data-image="/images/FCN.png"><i class="fab fa-weibo fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Blogger" data-sharer="blogger" data-url="http://jqc8438.github.io/2020/09/fcn/" data-title="【论文笔记】FCN" data-description="Fully Convolutional Networks for Semantic Segmentation "><i class="fab fa-blogger fa-fw"></i></a><a href="javascript:void(0);" title="分享到 百度" data-sharer="baidu" data-url="http://jqc8438.github.io/2020/09/fcn/" data-title="【论文笔记】FCN"><i data-svg-src="/lib/simple-icons/icons/baidu.min.svg"></i></a><a href="javascript:void(0);" title="分享到 Evernote" data-sharer="evernote" data-url="http://jqc8438.github.io/2020/09/fcn/" data-title="【论文笔记】FCN"><i class="fab fa-evernote fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/">语义分割</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/2020/09/deeplabv3p/" class="prev" rel="prev" title="【论文笔记】Deeplab v3&#43;"><i class="fas fa-angle-left fa-fw"></i>【论文笔记】Deeplab v3&#43;</a>
            <a href="/2020/11/hrnet/" class="next" rel="next" title="【论文笔记】HRNet">【论文笔记】HRNet<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">由 <a href="https://gohugo.io/" target="_blank" rel="noopener noreferrer" title="Hugo 0.89.4">Hugo</a> 驱动 | 主题 - <a href="https://github.com/sunt-programator/CodeIT" target="_blank" rel="noopener noreferrer" title="CodeIT 0.2.10"><i class="fas fa-laptop-code fa-fw"></i> CodeIT</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2020 - 2021</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank" rel="noopener noreferrer">jinhaha</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript" src="/lib/cookieconsent/cookieconsent.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":10},"comment":{},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
